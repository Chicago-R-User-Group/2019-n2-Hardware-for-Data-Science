# 2019-n2-Hardware-for-Data-Science

CRUG and ChiPy Data Science SIG joined together to deliver a hands-on meetup discussing a fundamental aspect in data science: hardware.


![](https://github.com/Chicago-R-User-Group/2019-n2-Hardware-for-Data-Science/blob/master/Hardware_Benchmarking/Images/Hardware_DataScience.png)
    
​
Whatever your language, at some point the code is processed on Silica and metal. Considering ever growing data sets, what are the implications for working with the standard issue 8gb laptop, and what attributes should you consider in your next computer? Join us for a discussion on the latest in hardware for Data Science to find out!


## Speakers

### Parfait Gasana

Parfait kicked off the meetup by analyzing hardware benchmarking results from R and Python data analytics simulations. He showed how processing time and memory usage varies with hardware specs: available RAM, virtual memory, 32/64-bit architecture, OS type and version, number of cores, and core speed.


### Seth Carpenter of FHLBC 

Seth discussed how and when to use Amazon Web Services (renting someone else’s hardware) and how to do so using Python.


### Justin Shea 

Justin discussed his recent custom build containing an AMD Threadripper 1950x processor. This newer chip contains 16 cores for parallel processing, offering greater performance than its Intel counterpart, at a fraction of the cost.


### Brian Peterson of Heymeyer trading + investments 

Brian cracked open a desktop built for modeling high-frequency time series data and discuss its components. As someone that routinely process greater amounts of data than can be contained in RAM, he offered the practitioners point of view on hardware choices.



